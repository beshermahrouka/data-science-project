# -*- coding: utf-8 -*-
"""during-covid19.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IX53CAd_LpKMkd1uN8WqKhFF_T4t2giP
"""

import networkx as nx 
import pandas as pd
from pathlib import Path
import matplotlib.pyplot as plt
import operator
import numpy as np
import collections as cs

from google.colab import drive
drive.mount('/content/drive')

flightlist2 = pd.concat(
    pd.read_csv(file, parse_dates=["firstseen", "lastseen", "day"])
    for file in Path("#").glob("flightlist_*.csv.gz")
)

flightlist2.head()

edges2 = flightlist2[['origin','destination','callsign']]

edges2.dropna(inplace=True)
edges2

edges2.count()

edges2.to_csv('edge_list2.csv', index=False)

graph_type2 = nx.Graph()

#data2 = pd.read_csv('edge_list2.csv')

#extract the first three letters from callsign to get the airline company
#data2['callsign'] = data2['callsign'].str[0:3]
edges2['callsign'] = edges2['callsign'].str[0:3]

#create graph with the modified callsign is the weight of the graph
flight_graph2 = nx.from_pandas_edgelist(edges2, source = 'origin', target = 'destination' ,edge_attr='callsign', create_using = graph_type2 )

flight_graph2.edges

flight_graph2.nodes

flight_graph2.edges.data()

#calculate the number of flights for each airline company
data2 = edges2
df_top_airlines2 = data2['callsign'].value_counts().reset_index()
df_top_airlines2.rename(columns= {'callsign':'flightCount'}, inplace=True)
df_top_airlines2.rename(columns= {'index':'airlineCompany'}, inplace=True)
df_top_airlines2.to_csv('flight_count2.csv', index=True)

#plot the number of flights for each airline company 
df_flight_count = pd.read_csv("flight_count2.csv")
#top 30 airline companies
x = df_flight_count['airlineCompany'][0:31]
y =  df_flight_count['flightCount'][0:31]
plt.figure(figsize=(10,5))
plt.ylabel("Number of flights")
plt.xlabel("Aireline")
plt.plot(x,y)
plt.gcf().autofmt_xdate()
plt.tight_layout()
plt.savefig("df_flight_count2.pdf")
#plt.show()

#degree distribution of the network (airports not airline companies)
degree_frequencies = nx.degree_histogram(flight_graph2)
plt.ylabel("Frequency")
plt.xlabel("Node degree")
plt.plot(degree_frequencies)
plt.tight_layout()
plt.savefig("degree_dis2.pdf")
plt.show()

#get the degree for each node (airport) and sort them
degree = dict(flight_graph2.degree())
degree_sorted = sorted(degree.items(), key = operator.itemgetter(1), reverse=True)
degree_nodes = pd.DataFrame(degree_sorted, columns=["airport", "degree"])
# remove the NaN airport from data (non existing airport)
#degree_nodes = degree_nodes.drop(degree_nodes.index[0])
degree_nodes.to_csv('airpot_degree2.csv', index=True)
degree_nodes

#plot the sorted degree for different nodes (airport)

airport_degrees = pd.read_csv("airpot_degree2.csv")

x = airport_degrees['airport'][0:31]
y =  airport_degrees['degree'][0:31]
plt.figure(figsize=(10,5))
plt.ylabel("Number of flights")
plt.xlabel("Airport")
plt.plot(x,y)
plt.gcf().autofmt_xdate()
plt.tight_layout()
plt.savefig("df_airport_count2.pdf")
#plt.show()

#DON't RUN IT. Takes very long time !!!!!!!!!!!!!!!!
Gcc1 = sorted(nx.connected_components(flight_graph2), key=len, reverse=True)
giant_one = flight_graph2.subgraph(Gcc1[0])
nx.average_clustering(giant_one)
nx.average_shortest_path_length(giant_one)
nx.diameter(giant_one)

#new code
Gcc1 = sorted(nx.connected_components(flight_graph2), key=len, reverse=True)
giant_one = flight_graph2.subgraph(Gcc1[0])
nx.average_clustering(giant_one)

#new code 
clusters_of_graph = nx.clustering(flight_graph2)
plt.ylabel("Clustering Coefficient")
plt.xlabel("Airport")
x_label_data = list(clusters_of_graph.keys())[:10]
y_label_data = list(clusters_of_graph.values())[:10]
#x_label_data = np.arange(len(x_label_data))
plt.bar(x_label_data, y_label_data, align="center", alpha=0.6)